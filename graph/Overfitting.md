Phenomen that happens when you rely too heavily on your training data. In [[K-Means Clustering]], it happens when you don't consider enough neighbors.



## Related concepts

- [[Underfitting]] - Model too simple
- [[Variance]] - Model sensitivity to training data
- [[Bias]] - Model systematic errors
- [[Learning curve]] - Training progress visualization
- [[Regularization]] - Preventing overfitting
- [[Cross validation]] - Detecting overfitting
- [[Model fit]] - Balance between over/underfitting
- [[Training data set]] - Data leading to overfitting
- [[Validation data]] - Detecting overfitting
- [[Pruning]] - Reducing overfitting in trees
