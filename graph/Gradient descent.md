---
typeOf: "[[Optimization algorithm]]"
uses: "[[Backpropagation]]"
requires: ["[[Learning rate]]", "[[Gradient]]", "[[loss function]]"]
minimizes: "[[Loss function]]"
updatesBy: "[[Weight updates]]"
variantsInclude: ["[[Batch gradient descent]]", "[[Stochastic gradient descent]]", "[[Mini-batch gradient descent]]"]
---

Iterative method to find the value of the weights that minimize the cost function. It is made possible by : 
* [[Learning rate]] that tells you how far to move on the gradient descent curve
* [[Gradient]] that tells you where direction to go 
* Iterations that tell you how many times you should move toward that direction.

