---
related_to:
  - "[[Agentic System]]"
  - "[[AgentOps]]"
  - "[[Agent Observability]]"
dependencies:
  - "[[Large Language Model]]"
category: Concepts Fondamentaux
tags:
  - AI_Agents
  - Autonomie
  - LLM
---

## Definitions

### Definition 1
An agent is a computational entity that perceives its environment through sensors and acts upon that environment through effectors, as conceptualized by Marvin Minsky in "The Society of Mind" (1986) and formalized in artificial intelligence research.

### Definition 2 
Système IA basé sur LLM qui peut agir de manière autonome, prendre des décisions et effectuer des tâches complexes avec une intervention humaine minimale.

## Caractéristiques principales :
- Autonomie dans la prise de décision
- Capacité d'interaction avec l'environnement
- Basé sur des modèles de langage de grande taille (LLM)
- Intervention humaine minimale requise

## Liens avec la taxonomie :
- Base des systèmes agentiques
- Élément central de la plateforme AgentOps
- Nécessite une observabilité complète pour la production

## Historical Development

1. **Early Concepts (1950s-1960s)**: Simple reactive machines and programs
2. **Minsky's Society of Mind (1986)**: Agents as fundamental cognitive building blocks
3. **Russell & Norvig Formalization (1995)**: "Artificial Intelligence: A Modern Approach" established modern agent definition

## Minsky's Original Concept

According to Minsky (1986):
- The mind consists of many small processes called "agents"
- Each agent performs a simple, specific task
- Intelligence emerges from interactions among agents
- No single agent is intelligent in isolation
- Complex behavior arises from the collaboration of simple agents

## Types of Agents

1. **Simple Reflex Agents**: React to current perceptions
2. **Model-Based Reflex Agents**: Maintain internal state
3. **Goal-Based Agents**: Act to achieve objectives
4. **Utility-Based Agents**: Maximize expected utility
5. **Learning Agents**: Improve performance over time

## Key Characteristics

1. **Autonomy**: Operate without direct intervention
2. **Reactivity**: Perceive and respond to environment
3. **Proactivity**: Exhibit goal-directed behavior
4. **Social Ability**: Interact with other agents

## PEAS Framework (Russell & Norvig)

Agents are defined by:
- **P**erformance measure
- **E**nvironment
- **A**ctuators
- **S**ensors

## Agent Architecture

1. **Perception Module**: Sensing the environment
2. **Decision Module**: Choosing actions
3. **Action Module**: Executing decisions
4. **Memory/State**: Storing information
5. **Learning Component**: Adapting behavior

## Properties of Intelligent Agents

1. **Situatedness**: Embedded in environment
2. **Embodiment**: Physical or virtual presence
3. **Adaptability**: Learning from experience
4. **Rationality**: Acting to maximize expected performance

## Applications

1. **Artificial Intelligence**:
   - Robotics
   - Game playing
   - Expert systems

2. **Multi-Agent Systems**:
   - Distributed problem solving
   - Swarm intelligence
   - Social simulation

3. **Software Agents**:
   - Web crawlers
   - Personal assistants
   - Recommendation systems

## Scientific Impact

The agent concept:
- Unified various AI approaches
- Provided framework for cognitive science
- Enabled distributed AI systems
- Influenced software architecture

## Theoretical Foundations

1. **Bounded Rationality** (Simon): Limited computational resources
2. **Intentional Stance** (Dennett): Treating systems as rational agents
3. **BDI Model** (Bratman): Beliefs, Desires, Intentions
4. **Actor Model** (Hewitt): Concurrent computation

## Related Concepts
- [[Society of Mind]]
- [[Artificial Intelligence]]
- [[Multi-agent systems]]
- [[Cognitive architecture]]
- [[Autonomous systems]]

## References

Minsky, M. (1986). The Society of Mind. New York: Simon & Schuster.

Russell, S., & Norvig, P. (1995). Artificial Intelligence: A Modern Approach. Prentice Hall.