Reaching fairness means having a system where user groups would receive similar levels of [[True Positive (TP)]] or have the same [[Inherent error]]. 

For that we determine significant groups then we define fairness : 
* same rate for every group ? 
* same rate for every group, but adjusting based on payback rates ? 

To resolve fairness issues : 
* change the data
* change the model
* change the system (if users use it in a different way)



## Related concepts (Adamic-Adar connections)

- [[Bias]] - Source of unfairness (Adamic-Adar: 0.641)
- [[Ethical risks]] - Results of unfairness (Adamic-Adar: 0.641)
- [[Accountable AI]] - Framework for fairness (Adamic-Adar: 0.641)
- [[Fair AI]] - Implementation of fairness
- [[Individual fairness]] - Specific fairness approach
