One interesting question is : 

> How many false positives can we expect from a AI detection tool given its [[Precision]], [[Accuracy]] and [[Recall]] measures ? 

And an even more fascinating question : 

> What the [[graph/Bayes' theorem|Bayes' theorem]] have to do with that ? 

Leading a a deep and very profund question : 

> Why is it that that we can determine P(A|B) from P(B|A) ? Meaning, in my case that we can determine the **probability** that a person indeed used AI to produce content (A) given it used a certain AI detection tool (B), from the known probability that the tool detected AI (B) content given a person used AI to produce content (A) ? 

For decision-makers, it comes down to one question : 

> From which probability threshold do we decide that the tool should not be used ([[Communicate uncertainty]]) ? For example, considering [[graph/Bayes' theorem|Bayes' theorem]], if there is a 30% chance that the person did not use AI, do we still trust the tool and decide to give a penalty to the person ? And if there is a 40% chance ? 


L'étrange ici vient du fait qu'on peut dire plus précisément ce qui risque de se passer (A) dans certaines circonstances (B) à partir d'observations passées du simple fait que "ce qui risque de se passer" (A) a bien été conditionné par certaines circonstances (B). 

Ce qui revient à dire que l'on peut préciser ce qui risque de se passer (détection de contenu rédigé par IA, A) dans certaines circonstances (utilisation de l'IA pour générer du contenu, B) si l'on sait que ce qui est arrivé l'a été dans certaines circonstances (B|A). 

**Ce qui revient encore à dire que nous pouvons plus précisément qualifier ce qui est probable à partir de ce qui est certain parce que passé**. Ce qui prouve que la connaissance du passé nous donne du pouvoir sur l'avenir avec une connaissance étonnante, qui est que plus nous savons de choses à propos du passé, moins nous risquons d'être surpris par l'avenir, si l'on en croit certaines théories cognitives qui voit l'esprit comme un réseau bayésien. 

Si l'on suit le fil, ce qui ferait de Compilatio IA un produit noble viendrait d'une fonctionnalité qui permettrait aux enseignants de renforcer la fiabilité de l'outil en venant renseigner via une mécanisme de [[Human-in-the-loop]] ou de [[Feedback loops]] le contenu des copies ou des passages dont il sait qu'il a été réalisé par une IA parce que l'auteur lui a signifié. La connaissance d'un passé permettant de qualifier plus précisément ce qui est probable à l'avenir. Compilatio IA aurait été noble donc s'il avait été un produit permettant de simplement collecter des contenu véritablement rédigés par des humains et des contenu véritablement rédigés par des IA. 