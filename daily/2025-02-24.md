One interesting question is : 

> How many false positives can we expect from a AI detection tool given its [[Precision]], [[Accuracy]] and [[Recall]] measures ? 

And an even more fascinating question : 

> What the [[graph/Bayes' theorem|Bayes' theorem]] have to do with that ? 

Leading a a deep and very profund question : 

> Why is it that that we can determine P(A|B) from P(B|A) ? Meaning, in my case that we can determine the **probability** that a person indeed used AI to produce content (A) given it used a certain AI detection tool (B), from the known probability that the tool detected AI (B) content given a person used AI to produce content (A) ? 

For decision-makers, it comes down to one question : 

> From which probability threshold do we decide that the tool should not be used ([[Communicate uncertainty]]) ? For example, considering [[graph/Bayes' theorem|Bayes' theorem]], if there is a 30% chance that the person did not use AI, do we still trust the tool and decide to give a penalty to the person ? And if there is a 40% chance ? 


L'étrange ici vient du fait qu'on peut dire plus précisément ce qui risque de se passer (A) dans certaines circonstances (B) à partir d'observations passées du simple fait que "ce qui risque de se passer" (A) a bien été conditionné par certaines circonstances (B). 
Ce qui revient à dire que l'on peut préciser ce qui risque de se passer (détection de contenu rédigé par IA, A) dans certaines circonstances (utilisation de l'IA pour générer du contenu, B) si l'on sait que ce qui est arrivé l'a été dans certaines circonstances (B|A). 
**Ce qui revient encore à dire que nous pouvons plus précisément qualifier ce qui est probable à partir de ce qui est certain.** Une